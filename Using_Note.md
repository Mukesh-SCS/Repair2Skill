
# ü™ë Repair2Skill Setup and Model Training Guide (Windows)

This guide walks you through setting up your environment and training the damage detection model to generate `part_detector.pth`.

---

## ‚úÖ Step 1: Set Up Python Environment (Windows)

### 1. Install Python 3.10 or 3.9
Download from: https://www.python.org/downloads/

> ‚ö†Ô∏è Do NOT use Python 3.11+ (Detectron2 is not supported)

### 2. Create a Virtual Environment
```bash
python3 -m venv venv
.\venv\Scripts\Activate
```

### 3. Install Dependencies
Make sure your `requirements.txt` looks like this (no detectron2 issues):

```txt
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
pillow>=8.0.0
numpy>=1.21.0
matplotlib>=3.3.0
openai>=1.0.0
python-dotenv>=0.19.0
requests>=2.25.0
json5>=0.9.0
tqdm>=4.62.0
albumentations>=1.0.0
pycocotools>=2.0.0
transformers>=4.20.0
# Optional: Raspberry Pi only
picamera2>=0.3.0; platform_system == "Linux"
open3d>=0.13.0
trimesh>=3.9.0
```

Then install:
```bash
pip install -r requirements.txt
```

---

## ‚úÖ Step 2: Train the Damage Detection Model

### 1. Generate Synthetic Data
```bash
python scripts/generate_synthetic_data.py --samples 500
```

This saves images and `annotations.json` to `./data/synthetic_damage/`.

### 2. Train the Model
```bash
python scripts/train_part_detector.py --data-dir ./data/synthetic_damage/
```

After training, your model will be saved to:
```
./models/damage_detection/part_detector.pth
```

---

## ‚úÖ Step 3: Set OpenAI API Key

Create a `.env` file in your project root with:
```env
OPENAI_API_KEY=sk-...
```

---

## ‚úÖ Step 4: Run the Pipeline

### 1. Place your test image
Example:
```
./data/user_images/my_broken_chair.jpg
```

### 2. Run:
```bash
python main.py --upload ./data/user_images/my_broken_chair.jpg
```

---

## üîç What Happens Internally

1. Loads your image
2. Uses the trained model (`part_detector.pth`) to detect parts
3. Sends it to OpenAI GPT-4o via `analyze_image`
4. Outputs JSON file `./outputs/stage1_parts.json`

---

## üß™ Output Example

Console:
```json
[{"name": "seat", "label": 0, "role": "support"}, {"name": "leg", "label": 1, "role": "support"}]
```

File:
```
./outputs/stage1_parts.json
```

---

## üõ† Troubleshooting

- **Model Not Found:** Make sure `part_detector.pth` exists in `./models/damage_detection/`
- **OpenAI Error:** Double check your `.env` key
- **Image Format:** Use `.jpg` or `.png`

---

## ‚úÖ Done!

You're ready to detect broken chair parts and build repair plans.





__________________________________________________________________________________
# ü™ë Repair2Skill Setup and Training Guide (Raspberry Pi 5)

This guide helps you set up the Repair2Skill pipeline and train a part damage detector on Raspberry Pi 5 using synthetic or real image data.

---

## ‚úÖ Step 1: Set Up Python & Virtual Environment

### 1. Install Python 3.9 (recommended for compatibility)

```bash
sudo apt update
sudo apt install python3.9 python3.9-venv python3.9-dev
```

### 2. Create and Activate Virtual Environment

```bash
python3.9 -m venv venv
source venv/bin/activate
```

---

## ‚úÖ Step 2: Install Dependencies

Ensure your `requirements.txt` includes this (Pi-compatible):

```txt
torch==2.0.1
torchvision==0.15.2
opencv-python-headless>=4.5.0
pillow>=8.0.0
numpy>=1.21.0
matplotlib>=3.3.0
openai>=1.0.0
python-dotenv>=0.19.0
requests>=2.25.0
json5>=0.9.0
tqdm>=4.62.0
albumentations>=1.0.0
pycocotools>=2.0.0
transformers>=4.20.0
picamera2>=0.3.0
open3d>=0.13.0
trimesh>=3.9.0
```

> ‚ö†Ô∏è Use `opencv-python-headless` instead of `opencv-python` to avoid GUI issues on Pi.

Install with:
```bash
pip install -r requirements.txt
```

---

## ‚úÖ Step 3: (Optional) Capture Real Images with Pi Camera

Use the GUI tool:

```bash
python scripts/real_data_collector.py
```

- Capture damaged parts using PiCamera2
- Annotate images and save bounding boxes

---

## ‚úÖ Step 4: Generate Synthetic Data

```bash
python scripts/generate_synthetic_data.py --samples 500
```

This will output:
```
./data/synthetic_damage/images/
./data/synthetic_damage/annotations.json
```

---

## ‚úÖ Step 5: Train the Part Detector Model

```bash
python scripts/train_part_detector.py --data-dir ./data/synthetic_damage/
```

Output model:
```
./models/damage_detection/part_detector.pth
```

---

## ‚úÖ Step 6: Set OpenAI API Key

Create a `.env` file in your project root with:

```env
OPENAI_API_KEY=sk-...
```

---

## ‚úÖ Step 7: Run Full Detection Pipeline

Put a test image here:
```
./data/user_images/my_broken_chair.jpg
```

Then run:
```bash
python main.py --upload ./data/user_images/my_broken_chair.jpg
```

---

## üõ† Troubleshooting (Pi)

- **Camera errors?** Make sure `libcamera` is working and `picamera2` is installed
- **Slow training?** Use fewer samples like `--samples 200`
- **Torch issues?** Use pre-built wheels for ARM64 from [https://github.com/nmilosev/pytorch-arm-builds](https://github.com/nmilosev/pytorch-arm-builds)

---


# ğŸ› ï¸ Repair2Skill on Raspberry Pi 5

**Repair2Skill** is an AI-powered framework that enables robots (or intelligent agents) to detect and plan repairs for broken furniture parts. Inspired by [Manual2Skill (RSS 2025)](https://github.com/owensun2004/Manual2Skill), this project extends the original idea to handle **furniture repair** by using a camera, part detection, and **vision-language models (VLMs)** like GPT-4o.

This implementation runs on a **Raspberry Pi 5** equipped with a camera for real-time image capture.

---

## ğŸ§  What It Does

- Captures an image of a **broken chair** using a Pi Camera or uploaded image.
- Uses a trained **Faster R-CNN** model to detect damaged parts.
- Sends detection results to **GPT-4o** via OpenAI API to generate a **step-by-step repair plan**.
- Generates a **visual repair graph** for robotic or manual execution.
- Optionally executes repair plans step-by-step via an executor.

---

## ğŸ“ Project Structure
```bash
FurnitureRepairModel/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ partnet_data/
â”‚   â”œâ”€â”€ ikea_manuals/
â”‚   â”œâ”€â”€ synthetic_damage/
â”‚   â””â”€â”€ user_images/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ damage_detection/
â”‚   â”œâ”€â”€ pose_estimation/
â”‚   â””â”€â”€ openai_integration/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_synthetic_data.py
â”‚   â”œâ”€â”€ train_part_detector.py
â”‚   â”œâ”€â”€ train_detector_frcnn.py
â”‚   â”œâ”€â”€ detect_damage.py
â”‚   â”œâ”€â”€ generate_repair_plan.py
â”‚   â”œâ”€â”€ render_visual_guidance.py
â”‚   â”œâ”€â”€ capture_image.py
â”‚   â”œâ”€â”€ repair_executor.py
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â”œâ”€â”€ data_augmentation.py
â”‚   â”œâ”€â”€ real_data_collector.py
â”‚   â””â”€â”€ model_optimization.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ assembly_plan_utils.py
â”‚   â”œâ”€â”€ visualization_utils.py
â”‚   â””â”€â”€ openai_utils.py
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ model_config.yaml
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

---

## âš™ï¸ How It Works

You can run the pipeline either with a captured image from the Raspberry Pi camera or an uploaded image.

### ğŸ”´ Option 1: Use Pi Camera
```bash
python main.py --camera
```

### ğŸ”µ Option 2: Upload an Image
```bash
python main.py --upload ./data/user_images/my_broken_chair.jpg
```

### The pipeline will:
- Detect broken parts using `Faster R-CNN`
- Generate repair steps using `OpenAI GPT-4`
- Output a repair graph for planning or robotics
- Render visual repair guides per part

---

## ğŸ§ª Other Tools & Utilities

- `train_detector_frcnn.py`: Train damage detection using Faster R-CNN.
- `evaluate_model.py`: Evaluate trained models on test data.
- `data_augmentation.py`: Augment datasets using albumentations.
- `real_data_collector.py`: Collect & label real-world damaged furniture samples.
- `model_optimization.py`: Quantize/prune models for Raspberry Pi deployment.
- `repair_executor.py`: Simulate or perform repair steps based on generated graph.
- `pose_estimation/estimate_pose.py`: Placeholder for future pose estimation integration.

---

## ğŸ› ï¸ Setup Instructions

1. Clone and set up the environment
```bash
git clone <this_repo>
cd FurnitureRepairModel
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

2. Add your OpenAI API Key in `.env`
```
OPENAI_API_KEY=your-api-key-here
```

---

## ğŸ“š References
- Manual2Skill (RSS 2025): https://github.com/owensun2004/Manual2Skill
- PartNet Dataset (CVPR 2019): https://github.com/daerduoCarey/partnet_dataset
- IKEA-Manual Dataset (NeurIPS 2022): https://cs.stanford.edu/~kaichun/ikea.html
- Furniture-Assembly-Web Demo: https://owensun2004.github.io/Furniture-Assembly-Web/
